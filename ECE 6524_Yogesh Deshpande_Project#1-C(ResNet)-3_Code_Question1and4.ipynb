{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL Project1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Project 2: Question 1"
      ],
      "metadata": {
        "id": "smjkb2ag-S0m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "#import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "#from keras.datasets import cifar100 #Replace use\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Dense, Conv2D, BatchNormalization, Activation\n",
        "from tensorflow.keras.layers import AveragePooling2D, Input, Flatten\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "def load_dataset():\n",
        "  (trainX, trainY), (testX, testY) = cifar10.load_data()\n",
        "  #(trainX, trainY), (testX, testY) = cifar100.load_data(label_mode=\"fine\") #Replace use\n",
        "  num_labels = len(np.unique(trainY))\n",
        "  trainY = to_categorical(trainY)\n",
        "  testY = to_categorical(testY)\n",
        "  return trainX, trainY, testX, testY, num_labels\n",
        "\n",
        "def prep_pixels(train, test):\n",
        "  train_norm = train.astype('float32')\n",
        "  test_norm = test.astype('float32')\n",
        "  # normalize\n",
        "  train_norm = train_norm / 255.0\n",
        "  test_norm = test_norm / 255.0\n",
        "  return train_norm, test_norm\n",
        "\n",
        "def lr_schedule(epoch):\n",
        "  lr = 1e-3\n",
        "  if epoch > 180:\n",
        "    lr *= 0.5e-3\n",
        "  elif epoch > 160:\n",
        "    lr *= 1e-3\n",
        "  elif epoch > 120:\n",
        "    lr *= 1e-2\n",
        "  elif epoch > 80:\n",
        "    lr *= 1e-1\n",
        "  print('Learning rate: ', lr)\n",
        "  return lr\n",
        "\n",
        "\n",
        "def resnet_layer(inputs,\n",
        "                 num_filters,\n",
        "                 kernel_size=3,\n",
        "                 strides=1,\n",
        "                 activation='relu',\n",
        "                 batch_normalization=True,\n",
        "                 conv_first=True):\n",
        "\n",
        "  conv = Conv2D(num_filters,\n",
        "                kernel_size=kernel_size,\n",
        "                strides=strides,\n",
        "                padding='same',\n",
        "                kernel_initializer='he_normal',\n",
        "                kernel_regularizer=l2(1e-4))\n",
        "\n",
        "  x = inputs\n",
        "  if conv_first:\n",
        "    x = conv(x)\n",
        "    if batch_normalization:\n",
        "      x = BatchNormalization()(x)\n",
        "    if activation is not None:\n",
        "      x = Activation(activation)(x)\n",
        "  else:\n",
        "    if batch_normalization:\n",
        "      x = BatchNormalization()(x)\n",
        "    if activation is not None:\n",
        "      x = Activation(activation)(x)\n",
        "    x = conv(x)\n",
        "  return x\n",
        "\n",
        "\n",
        "def resnet_v1(input_shape, n_val, num_classes, filter_size, no_resblk, optm):\n",
        "  num_filters = filter_size\n",
        "\n",
        "  inputs = Input(shape=input_shape)\n",
        "  x = resnet_layer(inputs=inputs, num_filters=num_filters)\n",
        "  for stack in range(no_resblk):\n",
        "    for res_block in range(n_val):\n",
        "      strides = 1\n",
        "      if stack > 0 and res_block == 0:\n",
        "        strides = 2\n",
        "      y = resnet_layer(inputs=x,\n",
        "                      num_filters=num_filters,\n",
        "                      strides=strides)\n",
        "      y = resnet_layer(inputs=y,\n",
        "                      num_filters=num_filters,\n",
        "                      activation=None)\n",
        "      if stack > 0 and res_block == 0:\n",
        "        x = resnet_layer(inputs=x,\n",
        "                         num_filters=num_filters,\n",
        "                         kernel_size=1,\n",
        "                         strides=strides,\n",
        "                         activation=None,\n",
        "                         batch_normalization=False)\n",
        "      x = keras.layers.add([x, y])\n",
        "      x = Activation('relu')(x)\n",
        "    num_filters *= 2\n",
        "\n",
        "  if no_resblk == 3:\n",
        "      x = AveragePooling2D(pool_size=8)(x)\n",
        "  else:\n",
        "      x = AveragePooling2D(pool_size=4)(x)\n",
        "  y = Flatten()(x)\n",
        "  outputs = Dense(num_classes,\n",
        "                  activation='softmax',\n",
        "                  kernel_initializer='he_normal')(y)\n",
        "\n",
        "  # Instantiate model.\n",
        "  model = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "  if optm == 'SGD':\n",
        "    opt = SGD(learning_rate=lr_schedule(0), momentum=0.9)\n",
        "  elif optm == 'ADAM':\n",
        "    opt = Adam(learning_rate=lr_schedule(0))\n",
        "  elif optm == 'RMSProp':\n",
        "    opt = RMSprop(learning_rate=lr_schedule(0), momentum=0.9)\n",
        "  model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "  return model\n",
        "\n",
        "\n",
        "trainX, trainY, testX, testY, num_labels = load_dataset()\n",
        "trainX, testX = prep_pixels(trainX, testX)\n",
        "image_size = trainX.shape[1]\n",
        "\n",
        "model = resnet_v1(input_shape=(image_size, image_size, 3), n_val=3, num_classes=num_labels, filter_size=16, no_resblk = 3, optm='ADAM')\n",
        "history = model.fit(trainX, trainY, epochs=100, batch_size=32, validation_data=(testX, testY), shuffle=True)\n",
        "\n",
        "_, acc = model.evaluate(testX, testY, verbose=0)\n",
        "print('> %.3f' % (acc * 100.0))\n"
      ],
      "metadata": {
        "id": "nsCwM_PQ-XKv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot\n",
        "\n",
        "def observe_plot(history):\n",
        "\t# plot loss\n",
        "\tpyplot.subplot(211)\n",
        "\tpyplot.title('Categorical Cross Entropy Loss')\n",
        "\tpyplot.plot(history.history['loss'], color='blue', label='train')\n",
        "\tpyplot.plot(history.history['val_loss'], color='orange', label='test')\n",
        "\t# plot accuracy\n",
        "\tpyplot.subplot(212)\n",
        "\tpyplot.title('Classification Accuracy')\n",
        "\tpyplot.plot(history.history['accuracy'], color='blue', label='train')\n",
        "\tpyplot.plot(history.history['val_accuracy'], color='orange', label='test')\n",
        " \n",
        "observe_plot(history)"
      ],
      "metadata": {
        "id": "tZpm4Nrz_ekp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "#import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from keras.datasets import cifar100 #Replace use\n",
        "#from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Dense, Conv2D, BatchNormalization, Activation\n",
        "from tensorflow.keras.layers import AveragePooling2D, Input, Flatten\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "def load_dataset():\n",
        "  #(trainX, trainY), (testX, testY) = cifar10.load_data()\n",
        "  (trainX, trainY), (testX, testY) = cifar100.load_data(label_mode=\"fine\") #Replace use\n",
        "  num_labels = len(np.unique(trainY))\n",
        "  trainY = to_categorical(trainY)\n",
        "  testY = to_categorical(testY)\n",
        "  return trainX, trainY, testX, testY, num_labels\n",
        "\n",
        "def prep_pixels(train, test):\n",
        "  train_norm = train.astype('float32')\n",
        "  test_norm = test.astype('float32')\n",
        "  # normalize\n",
        "  train_norm = train_norm / 255.0\n",
        "  test_norm = test_norm / 255.0\n",
        "  return train_norm, test_norm\n",
        "\n",
        "def lr_schedule(epoch):\n",
        "  lr = 1e-3\n",
        "  if epoch > 180:\n",
        "    lr *= 0.5e-3\n",
        "  elif epoch > 160:\n",
        "    lr *= 1e-3\n",
        "  elif epoch > 120:\n",
        "    lr *= 1e-2\n",
        "  elif epoch > 80:\n",
        "    lr *= 1e-1\n",
        "  print('Learning rate: ', lr)\n",
        "  return lr\n",
        "\n",
        "\n",
        "def resnet_layer(inputs,\n",
        "                 num_filters,\n",
        "                 kernel_size=3,\n",
        "                 strides=1,\n",
        "                 activation='relu',\n",
        "                 batch_normalization=True,\n",
        "                 conv_first=True):\n",
        "\n",
        "  conv = Conv2D(num_filters,\n",
        "                kernel_size=kernel_size,\n",
        "                strides=strides,\n",
        "                padding='same',\n",
        "                kernel_initializer='he_normal',\n",
        "                kernel_regularizer=l2(1e-4))\n",
        "\n",
        "  x = inputs\n",
        "  if conv_first:\n",
        "    x = conv(x)\n",
        "    if batch_normalization:\n",
        "      x = BatchNormalization()(x)\n",
        "    if activation is not None:\n",
        "      x = Activation(activation)(x)\n",
        "  else:\n",
        "    if batch_normalization:\n",
        "      x = BatchNormalization()(x)\n",
        "    if activation is not None:\n",
        "      x = Activation(activation)(x)\n",
        "    x = conv(x)\n",
        "  return x\n",
        "\n",
        "\n",
        "def resnet_v1(input_shape, n_val, num_classes, filter_size, no_resblk, optm):\n",
        "  num_filters = filter_size\n",
        "\n",
        "  inputs = Input(shape=input_shape)\n",
        "  x = resnet_layer(inputs=inputs, num_filters=num_filters)\n",
        "  for stack in range(no_resblk):\n",
        "    for res_block in range(n_val):\n",
        "      strides = 1\n",
        "      if stack > 0 and res_block == 0:\n",
        "        strides = 2\n",
        "      y = resnet_layer(inputs=x,\n",
        "                      num_filters=num_filters,\n",
        "                      strides=strides)\n",
        "      y = resnet_layer(inputs=y,\n",
        "                      num_filters=num_filters,\n",
        "                      activation=None)\n",
        "      if stack > 0 and res_block == 0:\n",
        "        x = resnet_layer(inputs=x,\n",
        "                         num_filters=num_filters,\n",
        "                         kernel_size=1,\n",
        "                         strides=strides,\n",
        "                         activation=None,\n",
        "                         batch_normalization=False)\n",
        "      x = keras.layers.add([x, y])\n",
        "      x = Activation('relu')(x)\n",
        "    num_filters *= 2\n",
        "\n",
        "  if no_resblk == 3:\n",
        "      x = AveragePooling2D(pool_size=8)(x)\n",
        "  else:\n",
        "      x = AveragePooling2D(pool_size=4)(x)\n",
        "  y = Flatten()(x)\n",
        "  outputs = Dense(num_classes,\n",
        "                  activation='softmax',\n",
        "                  kernel_initializer='he_normal')(y)\n",
        "\n",
        "  model = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "  if optm == 'SGD':\n",
        "    opt = SGD(learning_rate=lr_schedule(0), momentum=0.9)\n",
        "  elif optm == 'ADAM':\n",
        "    opt = Adam(learning_rate=lr_schedule(0))\n",
        "  elif optm == 'RMSProp':\n",
        "    opt = RMSprop(learning_rate=lr_schedule(0), momentum=0.9)\n",
        "  model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "  return model\n",
        "\n",
        "trainX, trainY, testX, testY, num_labels = load_dataset()\n",
        "trainX, testX = prep_pixels(trainX, testX)\n",
        "image_size = trainX.shape[1]\n",
        "\n",
        "model = resnet_v1(input_shape=(image_size, image_size, 3), n_val=3, num_classes=num_labels, filter_size=16, no_resblk = 3, optm='ADAM')\n",
        "history = model.fit(trainX, trainY, epochs=100, batch_size=32, validation_data=(testX, testY), shuffle=True)\n",
        "\n",
        "_, acc = model.evaluate(testX, testY, verbose=0)\n",
        "print('> %.3f' % (acc * 100.0))"
      ],
      "metadata": {
        "id": "nG11-ZyM_kl3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot\n",
        "\n",
        "def observe_plot(history):\n",
        "\t# plot loss\n",
        "\tpyplot.subplot(211)\n",
        "\tpyplot.title('Categorical Cross Entropy Loss')\n",
        "\tpyplot.plot(history.history['loss'], color='blue', label='train')\n",
        "\tpyplot.plot(history.history['val_loss'], color='orange', label='test')\n",
        "\t# plot accuracy\n",
        "\tpyplot.subplot(212)\n",
        "\tpyplot.title('Classification Accuracy')\n",
        "\tpyplot.plot(history.history['accuracy'], color='blue', label='train')\n",
        "\tpyplot.plot(history.history['val_accuracy'], color='orange', label='test')\n",
        " \n",
        "observe_plot(history)"
      ],
      "metadata": {
        "id": "rcWofGZM_pMJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Project 2: Question 3"
      ],
      "metadata": {
        "id": "3FVvAIPdimWD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "#from keras.datasets import cifar100 #Replace use\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "\n",
        "def load_dataset():\n",
        "  (trainX, trainY), (testX, testY) = cifar10.load_data()\n",
        "  #(trainX, trainY), (testX, testY) = cifar100.load_data(label_mode=\"fine\") #Replace use\n",
        "  num_labels = len(np.unique(trainY))\n",
        "  trainY = to_categorical(trainY)\n",
        "  testY = to_categorical(testY)\n",
        "  return trainX, trainY, testX, testY, num_labels\n",
        "\n",
        "def ResNet_50(num_labels, optm):\n",
        "  \n",
        "  baseModel = ResNet50(weights=\"imagenet\", include_top=False, input_tensor=Input(shape=(32,32,3)))\n",
        "  \n",
        "  headModel = baseModel.output\n",
        "  headModel = tf.keras.layers.GlobalAveragePooling2D()(headModel)\n",
        "  headModel = tf.keras.layers.Dense(1024, activation=\"relu\")(headModel)\n",
        "  headModel = tf.keras.layers.Dense(num_labels, activation=\"softmax\")(headModel)\n",
        "\n",
        "  model = tf.keras.models.Model(inputs=baseModel.input, outputs=headModel)\n",
        "  \n",
        "  for layer in baseModel.layers:\n",
        "    layer.trainable = False\n",
        "  \n",
        "  if optm == 'SGD':\n",
        "    opt = SGD(lr=0.0001, momentum=0.9)\n",
        "  elif optm == 'ADAM':\n",
        "    opt = Adam(learning_rate=0.01)\n",
        "  elif optm == 'RMSProp':\n",
        "    opt = RMSprop(lr=0.1, momentum=0.9)\n",
        "  model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "  return model\n",
        "\n",
        "def run_main():\n",
        "  trainX, trainY, testX, testY, num_labels = load_dataset()\n",
        "  image_size = trainX.shape[1]\n",
        "  \n",
        "  model = ResNet_50(num_labels, 'SGD')\n",
        "  \n",
        "  trainX = tf.keras.applications.resnet50.preprocess_input(trainX, data_format=None)\n",
        "  testX = tf.keras.applications.resnet50.preprocess_input(testX, data_format=None)\n",
        "\n",
        "  history = model.fit(trainX, trainY, epochs=100, batch_size=16, validation_data=(testX, testY))\n",
        "\n",
        "  _, acc = model.evaluate(testX, testY, verbose=0)\n",
        "\n",
        "  print('> %.3f' % (acc * 100.0))\n",
        "\n",
        "run_main()"
      ],
      "metadata": {
        "id": "sn2sjObzJsET"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from keras.datasets import cifar100 #Replace use\n",
        "#from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "\n",
        "def load_dataset():\n",
        "  #(trainX, trainY), (testX, testY) = cifar10.load_data()\n",
        "  (trainX, trainY), (testX, testY) = cifar100.load_data(label_mode=\"fine\") #Replace use\n",
        "  num_labels = len(np.unique(trainY))\n",
        "  trainY = to_categorical(trainY)\n",
        "  testY = to_categorical(testY)\n",
        "  return trainX, trainY, testX, testY, num_labels\n",
        "\n",
        "def ResNet_50(num_labels, optm):\n",
        "  \n",
        "  baseModel = ResNet50(weights=\"imagenet\", include_top=False, input_tensor=Input(shape=(32,32,3)))\n",
        "  \n",
        "  headModel = baseModel.output\n",
        "  headModel = tf.keras.layers.GlobalAveragePooling2D()(headModel)\n",
        "  headModel = tf.keras.layers.Dense(1024, activation=\"relu\")(headModel)\n",
        "  headModel = tf.keras.layers.Dense(num_labels, activation=\"softmax\")(headModel)\n",
        "\n",
        "  model = tf.keras.models.Model(inputs=baseModel.input, outputs=headModel)\n",
        "  \n",
        "  for layer in baseModel.layers:\n",
        "    layer.trainable = False\n",
        "  \n",
        "  if optm == 'SGD':\n",
        "    opt = SGD(lr=0.0001, momentum=0.9)\n",
        "  elif optm == 'ADAM':\n",
        "    opt = Adam(learning_rate=0.01)\n",
        "  elif optm == 'RMSProp':\n",
        "    opt = RMSprop(lr=0.1, momentum=0.9)\n",
        "  model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "  return model\n",
        "\n",
        "def run_main():\n",
        "  trainX, trainY, testX, testY, num_labels = load_dataset()\n",
        "  image_size = trainX.shape[1]\n",
        "  \n",
        "  model = ResNet_50(num_labels, 'SGD')\n",
        "  \n",
        "  trainX = tf.keras.applications.resnet50.preprocess_input(trainX, data_format=None)\n",
        "  testX = tf.keras.applications.resnet50.preprocess_input(testX, data_format=None)\n",
        "\n",
        "  history = model.fit(trainX, trainY, epochs=100, batch_size=16, validation_data=(testX, testY))\n",
        "\n",
        "  _, acc = model.evaluate(testX, testY, verbose=0)\n",
        "\n",
        "  print('> %.3f' % (acc * 100.0))\n",
        "\n",
        "run_main()"
      ],
      "metadata": {
        "id": "sf3mEYXiTC1y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}